# Data Directory

This directory contains raw and processed data for the NLP multi-type classification project.

---

## Directory Structure

```
data/
‚îú‚îÄ‚îÄ raw/                    # Original, unprocessed data files
‚îÇ   ‚îî‚îÄ‚îÄ (place your raw data here)
‚îÇ
‚îî‚îÄ‚îÄ processed/              # Generated by data_prep.py
    ‚îú‚îÄ‚îÄ train_4class.csv    # Training split (70%)
    ‚îú‚îÄ‚îÄ val_4class.csv      # Validation split (15%)
    ‚îî‚îÄ‚îÄ test_4class.csv     # Test split (15%)
```

---

## Raw Data

### Where to Place Raw Data

Place your source data files in the `raw/` subdirectory:

```bash
cp /path/to/your/dataset.json data/raw/
# or
cp /path/to/your/dataset.csv data/raw/
```

### Expected Raw Data Format

Raw data should be organized by **families**, where each family represents variants of the same base content.

#### Required Fields

| Field | Type | Description |
|-------|------|-------------|
| `family_id` | string | Unique identifier for grouping samples |
| `type1` | string or null | Human original text |
| `type2` | string or null | LLM generated text |
| `type3` | string or null | Human paraphrased text |
| `type4` | string or null | LLM paraphrased text |

#### Example (JSON)

```json
[
  {
    "family_id": "fam_001",
    "type1": "The weather today is sunny and warm.",
    "type2": "Today's weather is characterized by sunshine and warmth.",
    "type3": "It's a sunny, warm day outside.",
    "type4": "The current meteorological conditions feature abundant sunshine."
  },
  {
    "family_id": "fam_002",
    "type1": "Machine learning is a subset of artificial intelligence.",
    "type2": "ML represents a branch of AI technology.",
    "type3": "Artificial intelligence includes machine learning as a component.",
    "type4": null
  }
]
```

#### Example (CSV)

```csv
family_id,type1,type2,type3,type4
fam_001,"The weather today is sunny and warm.","Today's weather is characterized by sunshine and warmth.","It's a sunny, warm day outside.","The current meteorological conditions feature abundant sunshine."
fam_002,"Machine learning is a subset of artificial intelligence.","ML represents a branch of AI technology.","Artificial intelligence includes machine learning as a component.",
```

**Note:** Not all families need to have all four types. Missing types (null values) are acceptable.

---

## Processed Data

### How Processed Data is Generated

Processed data is created by running:

```bash
python src/data_prep.py --config configs/data_config.yaml
```

This script:
1. Reads raw data from `data/raw/`
2. Unpacks families into single-sentence samples
3. Performs family-aware splitting (70% train, 15% val, 15% test)
4. Validates data integrity (no leakage, valid labels, etc.)
5. Writes CSVs to `data/processed/`

### Processed Data Format

Each CSV file contains individual classification samples with the following schema:

| Column | Type | Description |
|--------|------|-------------|
| `family_id` | string | Links back to original family |
| `text` | string | The sentence to classify |
| `label` | string | One of {T1, T2, T3, T4} |
| `text_len_char` | int (optional) | Character count |
| `text_len_word` | int (optional) | Word count |

#### Example (train_4class.csv)

```csv
family_id,text,label,text_len_char,text_len_word
fam_001,"The weather today is sunny and warm.",T1,39,7
fam_001,"Today's weather is characterized by sunshine and warmth.",T2,58,8
fam_001,"It's a sunny, warm day outside.",T3,33,6
fam_001,"The current meteorological conditions feature abundant sunshine.",T4,65,9
fam_002,"Machine learning is a subset of artificial intelligence.",T1,58,9
fam_002,"ML represents a branch of AI technology.",T2,41,7
fam_002,"Artificial intelligence includes machine learning as a component.",T3,65,9
```

**Critical:** All samples with the same `family_id` reside in the **same split** (no leakage).

---

## Label Mapping

| String Label | Integer | Description |
|--------------|---------|-------------|
| **T1** | 0 | Human Original |
| **T2** | 1 | LLM Generated |
| **T3** | 2 | Human Paraphrased |
| **T4** | 3 | LLM Paraphrased |

---

## Data Validation

### Validation Checks Performed

The data preparation script validates:

‚úÖ **Label validity:** All labels in {T1, T2, T3, T4}  
‚úÖ **Non-empty text:** All texts are non-empty after stripping whitespace  
‚úÖ **No leakage:** Each `family_id` appears in exactly one split  
‚úÖ **Text length:** All texts ‚â§ 4000 characters (configurable)  

### Warning Checks

‚ö†Ô∏è **Class imbalance:** Warn if any class < 10% of total  
‚ö†Ô∏è **Text length outliers:** Warn if text < 10 or > 2000 characters  
‚ö†Ô∏è **Duplicates:** Count exact duplicate texts  

---

## Data Statistics (Example)

After running data preparation, you should see output like:

```
Train split: 2660 samples (700 families)
Val split:   570 samples (150 families)
Test split:  570 samples (150 families)

Class distribution (train):
  T1: 720 (27.1%)
  T2: 680 (25.6%)
  T3: 310 (11.7%)
  T4: 950 (35.7%)

Text length statistics (train):
  Mean: 87.3 characters (14.2 words)
  Median: 76 characters (12 words)
  Min: 15 characters (3 words)
  Max: 312 characters (48 words)
```

---

## Split Determinism

### Fixed Seed for Reproducibility

The split uses a **fixed random seed** (default: 42) to ensure:
- Same splits generated across multiple runs
- Reproducible experiments
- Consistent results

To change the seed, edit `configs/data_config.yaml`:

```yaml
split:
  seed: 42  # Change this to generate different splits
```

**Warning:** Changing the seed will produce different train/val/test splits.

---

## Data Quality Best Practices

### Before Running Data Preparation

1. **Inspect raw data:**
   - Check for missing `family_id` values
   - Verify text fields are not empty
   - Ensure at least some families have all 4 types

2. **Check for duplicates:**
   - Look for duplicate `family_id` values
   - Identify duplicate text content

3. **Validate encoding:**
   - Ensure files are UTF-8 encoded
   - Check for special characters or control characters

### After Running Data Preparation

1. **Run EDA notebook:**
   ```bash
   jupyter notebook notebooks/00_eda.ipynb
   ```

2. **Verify leakage check passed:**
   - Look for "‚úì PASS: No family leakage detected" in output

3. **Review class distribution:**
   - Ensure all classes are represented
   - Check if imbalance is acceptable

4. **Inspect text lengths:**
   - Verify no extremely short or long texts
   - Review outliers manually

---

## Troubleshooting

### Issue: "No family leakage check failed"

**Cause:** Some `family_id` appears in multiple splits.

**Solution:**
- Check raw data for duplicate `family_id` values
- Verify `group_key: family_id` in `configs/data_config.yaml`
- Run with a different seed or fix data quality issues

### Issue: "Class T3 is X% (below 10% threshold)"

**Cause:** Class T3 is underrepresented in the dataset.

**Solution:**
- If T3 is genuinely rare, this is expected (just a warning)
- Consider collecting more T3 samples
- Use class weighting during training to compensate

### Issue: "Maximum text length exceeded"

**Cause:** Some texts are longer than `max_len_chars` (default: 4000).

**Solution:**
- Review the long texts manually (are they outliers?)
- Increase `max_len_chars` in `configs/data_config.yaml` if needed
- Or truncate/remove very long texts

---

## File Naming Conventions

- **Raw files:** Any name is acceptable (e.g., `data.json`, `dataset.csv`)
- **Processed files:** Fixed names (do not rename):
  - `train_4class.csv`
  - `val_4class.csv`
  - `test_4class.csv`

**Rationale:** Training scripts expect these exact file names.

---

## Backup and Version Control

### What to Version Control

‚úÖ **Raw data:** If small enough, commit to Git  
‚úÖ **Data preparation script:** `src/data_prep.py`  
‚úÖ **Config files:** `configs/data_config.yaml`  

### What NOT to Version Control

‚ùå **Processed data:** Large CSVs (regenerate as needed)  
‚ùå **Intermediate files:** Temporary processing artifacts  

**Recommendation:** Use `.gitignore` to exclude `data/processed/`:

```
# .gitignore
data/processed/
```

---

## Data Contract

For complete schema specifications, validation rules, and data contracts, see:

üìÑ [`docs/DATA_CONTRACT.md`](../docs/DATA_CONTRACT.md)

---

*Last updated: 2025-11-13*

