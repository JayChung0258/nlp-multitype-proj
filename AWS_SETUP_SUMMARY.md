# AWS EC2 Setup - Summary

## âœ… What Was Added

### 1. AWS Helper Scripts (`scripts/`)

- **`aws_ec2_setup.sh`** (4.8 KB) â€” Automated environment setup on fresh EC2 instance
- **`aws_sync_data.sh`** (3.0 KB) â€” Sync data between local and EC2 (bidirectional)
- **`aws_sync_results.sh`** (2.9 KB) â€” Download results from EC2 to local
- **`README.md`** â€” Documentation for all scripts

All scripts are executable (`chmod +x`) and tested.

### 2. AWS Configuration

- **`configs/aws_config.yaml`** â€” S3 settings, EC2 recommendations, cost tracking placeholders
- **`src/aws_utils.py`** â€” Lightweight utility functions for S3 and EC2 detection (with stubs for future expansion)

### 3. Comprehensive Documentation

- **`docs/RUNBOOK_AWS_EC2.md`** â€” Complete step-by-step guide for EC2 workflow:
  - Instance launch and configuration
  - Environment setup
  - Data transfer (SCP and S3)
  - Running experiments
  - Retrieving results
  - Cost optimization
  - Troubleshooting

### 4. Updated Files

- **`README.md`** â€” Added AWS EC2 Quick Start section
- **`.gitignore`** â€” Updated to exclude all large model files and checkpoints
- **`.gitattributes`** â€” Mark binary files properly

---

## ğŸš€ How to Use

### Local â†’ EC2 â†’ Results Workflow

**1. Setup EC2 (one-time):**
```bash
# Launch g4dn.xlarge via AWS Console
# SSH in and run:
./scripts/aws_ec2_setup.sh
```

**2. Upload data:**
```bash
# From local
./scripts/aws_sync_data.sh upload ubuntu@<EC2_IP> ~/.ssh/key.pem
```

**3. Train on EC2:**
```bash
# On EC2
python -m src.train_transformer --model_name distilbert-base-uncased
python -m src.train_transformer --model_name bert-base-uncased
python -m src.train_transformer --model_name roberta-base
```

**4. Download results:**
```bash
# From local
./scripts/aws_sync_results.sh ubuntu@<EC2_IP> ~/.ssh/key.pem
```

**5. Stop instance:**
```bash
aws ec2 stop-instances --instance-ids i-xxxxx
```

---

## ğŸ’° Cost Estimate

**Full experiment (4 transformer models on g4dn.xlarge):**
- Training time: ~2 hours
- **Cost (Spot):** ~$0.32
- **Cost (On-Demand):** ~$1.05

---

## âœ… Verification

### Local Workflows Still Work

âœ… Data preprocessing:
```bash
python -m src.data_prep
```

âœ… Baseline training:
```bash
python -m src.train_baseline
```

âœ… Transformer training:
```bash
python -m src.train_transformer --model_name distilbert-base-uncased
```

### AWS Utilities Work

âœ… Load AWS config:
```python
from src.aws_utils import load_aws_config
config = load_aws_config()
```

âœ… Detect EC2:
```python
from src.aws_utils import is_running_on_ec2
print(is_running_on_ec2())  # False on local, True on EC2
```

---

## ğŸ“ Directory Structure

```
nlp-multitype-proj/
â”œâ”€â”€ scripts/                  # NEW! AWS helper scripts
â”‚   â”œâ”€â”€ aws_ec2_setup.sh
â”‚   â”œâ”€â”€ aws_sync_data.sh
â”‚   â”œâ”€â”€ aws_sync_results.sh
â”‚   â””â”€â”€ README.md
â”œâ”€â”€ configs/
â”‚   â”œâ”€â”€ aws_config.yaml       # NEW! AWS configuration
â”‚   â””â”€â”€ ...
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ aws_utils.py          # NEW! AWS utility functions
â”‚   â”œâ”€â”€ train_baseline.py     # Works on EC2
â”‚   â”œâ”€â”€ train_transformer.py  # Works on EC2 (GPU auto-detected)
â”‚   â””â”€â”€ ...
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ RUNBOOK_AWS_EC2.md    # NEW! Comprehensive EC2 guide
â”‚   â””â”€â”€ ...
â””â”€â”€ ...
```

---

## ğŸ”’ Security

### What's Ignored in Git

âœ… Model files (`.safetensors`, `.bin`, `.joblib`)
âœ… Checkpoints and logs
âœ… Processed data (`.jsonl` files)
âœ… AWS credentials (`.pem`, `.aws/`)
âœ… Virtual environment (`venv/`)

### What's Tracked in Git

âœ… Source code
âœ… Configs (without secrets)
âœ… Documentation
âœ… Small results (metrics.json, reports, plots)
âœ… Scripts

---

## ğŸ“š Key Documentation

- **Local workflow:** `docs/RUNBOOK_LOCAL.md`
- **AWS EC2 workflow:** `docs/RUNBOOK_AWS_EC2.md`
- **Scripts usage:** `scripts/README.md`
- **Data preprocessing:** `docs/DATA_PREPROCESSING.md`

---

## âœ¨ Next Steps

1. âœ… Push code to GitHub
2. Launch EC2 instance (g4dn.xlarge recommended)
3. Run `scripts/aws_ec2_setup.sh` on EC2
4. Upload data using `scripts/aws_sync_data.sh`
5. Train all models on EC2
6. Download results using `scripts/aws_sync_results.sh`
7. Stop/terminate EC2 instance

---

**Status:** âœ… **AWS EC2-READY**

The repository is now fully configured for seamless local development and cloud-based GPU training!
