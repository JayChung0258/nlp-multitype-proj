# Figures Directory

This directory contains all generated plots and visualizations for the NLP multi-type classification project.

---

## Directory Structure

```
figures/
├── data/                   # EDA plots and data analysis
│   ├── class_distribution.png
│   ├── text_length_by_class.png
│   ├── text_length_histogram.png
│   └── ...
│
└── results/                # Model results and comparisons
    ├── confusion_matrix_bert.png
    ├── confusion_matrix_roberta.png
    ├── model_comparison_scatter.png
    ├── per_class_f1_comparison.png
    └── ...
```

---

## Data Visualizations

Generated by `notebooks/00_eda.ipynb` or `src/viz_utils.py`.

### Class Distribution

**File:** `data/class_distribution.png`

**Description:** Bar chart showing the proportion of each class (T1, T2, T3, T4) across train, validation, and test splits.

**Purpose:** Verify balanced representation of classes; identify class imbalance.

**Example:**

```
      Train    Val    Test
T1:   ████████ ████   ████
T2:   ████████ ████   ████
T3:   ███      ██     ██
T4:   ██████████ ████ ████
```

### Text Length Distribution

**File:** `data/text_length_by_class.png`

**Description:** Boxplot or violin plot showing word count (or character count) distribution per class.

**Purpose:** Identify if certain classes tend to be longer/shorter; detect outliers.

**Example:**

```
        T1        T2        T3        T4
        │         │         │         │
        ├─────┤   ├────┤    ├───┤     ├──────┤
   ─────┴─────────┴────────┴─────────┴──────── (word count)
```

### Text Length Histogram

**File:** `data/text_length_histogram.png`

**Description:** Histogram of text lengths (word count or character count) across all samples.

**Purpose:** Overall length distribution; identify common length ranges.

---

## Results Visualizations

Generated after training models (future implementation).

### Confusion Matrix

**Files:**
- `results/confusion_matrix_logreg.png`
- `results/confusion_matrix_bert.png`
- `results/confusion_matrix_roberta.png`
- etc.

**Description:** Heatmap showing predicted vs. actual class labels.

**Purpose:** Identify which classes are most often confused (e.g., T3 ↔ T4).

**Example:**

```
Confusion Matrix (BERT)
         Predicted
Actual    T1   T2   T3   T4
  T1    [142   2    3    5]
  T2    [  3 140    2    3]
  T3    [  8   5   45   10]
  T4    [  4   2   12  184]
```

### Model Comparison Scatter

**File:** `results/model_comparison_scatter.png`

**Description:** Scatter plot showing tradeoff between two metrics (e.g., Macro-F1 vs. inference latency).

**Purpose:** Identify Pareto-optimal models; visualize speed vs. accuracy tradeoffs.

**Example:**

```
Macro-F1
   0.90 │              ● RoBERTa
        │           ● BERT
   0.85 │        ● DistilBERT
        │
   0.80 │     ● XGBoost
        │  ● Logreg
        └──────────────────────── Latency (ms)
```

### Per-Class F1 Comparison

**File:** `results/per_class_f1_comparison.png`

**Description:** Grouped bar chart comparing F1 scores for each class across all models.

**Purpose:** Identify which models perform best on specific classes (e.g., T3 or T4).

**Example:**

```
F1 Score
   1.0 │
       │  ■ T1  ■ T2  ■ T3  ■ T4
   0.8 │  ████  ████  ██    ████
       │  ████  ████  ██    ████
   0.6 │  ████  ████  ██    ████
       │
   0.0 └─────────────────────────
         Logreg  BERT  RoBERTa
```

---

## Robustness Analysis

Generated during robustness testing (future).

### Perturbation Results

**File:** `results/perturbation_results.png`

**Description:** Bar chart showing performance drop after applying perturbations (lowercase, punctuation removal, synonym swap).

**Purpose:** Evaluate model robustness to text variations.

### Length-Stratified Performance

**File:** `results/length_stratified_f1.png`

**Description:** Line plot showing F1 score across text length buckets (short, medium, long).

**Purpose:** Identify if models struggle with certain text lengths.

---

## Figure Generation

### Manual Generation (Notebooks)

Run EDA notebook to generate data visualizations:

```bash
jupyter notebook notebooks/00_eda.ipynb
```

Figures will be saved to `figures/data/`.

### Automatic Generation (Scripts)

**Future:** Training scripts will automatically generate result plots:

```bash
python src/train_baseline.py --generate-plots
python src/train_transformer.py --generate-plots
```

Figures will be saved to `figures/results/`.

---

## Figure Format and Style

### Default Settings

From `configs/project.yaml`:

```yaml
figures:
  format: png
  dpi: 300
  style: whitegrid
  palette: deep
  figsize: [10, 6]
```

### Customization

To change figure style, edit `configs/project.yaml` or use `src/viz_utils.py` functions directly.

**Available styles:**
- `whitegrid` (default)
- `darkgrid`
- `white`
- `dark`
- `ticks`

**Available palettes:**
- `deep` (default)
- `muted`
- `pastel`
- `bright`
- `dark`
- `colorblind`

---

## Naming Conventions

### Data Figures

- `class_distribution.png` — Class proportions per split
- `text_length_by_class.png` — Length distribution per class
- `text_length_histogram.png` — Overall length distribution
- `duplicates_analysis.png` — Duplicate text analysis (if applicable)

### Results Figures

- `confusion_matrix_{model_name}.png` — Confusion matrix for specific model
- `model_comparison_scatter.png` — Multi-metric comparison scatter plot
- `per_class_f1_comparison.png` — Grouped bar chart of F1 per class
- `training_curves_{model_name}.png` — Training/validation curves (transformers)
- `latency_f1_tradeoff.png` — Speed vs. accuracy tradeoff

### Robustness Figures

- `perturbation_results.png` — Performance under perturbations
- `length_stratified_f1.png` — F1 across length buckets
- `error_analysis_{model_name}.png` — Error distribution or examples

---

## Usage Examples

### Generate Class Distribution Plot

```python
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# Load data
train_df = pd.read_csv('data/processed/train_4class.csv')
val_df = pd.read_csv('data/processed/val_4class.csv')
test_df = pd.read_csv('data/processed/test_4class.csv')

# Compute class counts
counts = {
    'Train': train_df['label'].value_counts().sort_index(),
    'Val': val_df['label'].value_counts().sort_index(),
    'Test': test_df['label'].value_counts().sort_index(),
}

# Plot
fig, ax = plt.subplots(figsize=(10, 6))
x = ['T1', 'T2', 'T3', 'T4']
width = 0.25
for i, (split_name, count_series) in enumerate(counts.items()):
    ax.bar([j + i*width for j in range(4)], count_series, width, label=split_name)

ax.set_xlabel('Class')
ax.set_ylabel('Count')
ax.set_title('Class Distribution Across Splits')
ax.set_xticks([j + width for j in range(4)])
ax.set_xticklabels(x)
ax.legend()
plt.tight_layout()
plt.savefig('figures/data/class_distribution.png', dpi=300)
plt.show()
```

### Generate Confusion Matrix Heatmap

```python
from sklearn.metrics import confusion_matrix
import seaborn as sns
import matplotlib.pyplot as plt

# Assume y_true and y_pred are available
cm = confusion_matrix(y_true, y_pred)

# Plot
fig, ax = plt.subplots(figsize=(8, 8))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', 
            xticklabels=['T1', 'T2', 'T3', 'T4'],
            yticklabels=['T1', 'T2', 'T3', 'T4'])
ax.set_xlabel('Predicted')
ax.set_ylabel('Actual')
ax.set_title('Confusion Matrix (BERT)')
plt.tight_layout()
plt.savefig('figures/results/confusion_matrix_bert.png', dpi=300)
plt.show()
```

---

## Version Control

### What to Version Control

✅ **Scripts that generate figures** (`src/viz_utils.py`, notebooks)  
✅ **Example figures** (a few representative plots for documentation)  

### What NOT to Version Control

❌ **All generated figures** (can be large and change frequently)  

**Recommendation:** Add to `.gitignore`:

```
# .gitignore
figures/data/*.png
figures/results/*.png
```

But keep one or two example figures for documentation.

---

## Troubleshooting

### Issue: Figures not displaying in notebook

**Solution:** Add `%matplotlib inline` at the top of the notebook.

### Issue: Figure text cut off

**Solution:** Use `plt.tight_layout()` before saving:

```python
plt.tight_layout()
plt.savefig('figures/data/my_plot.png', dpi=300, bbox_inches='tight')
```

### Issue: Low-quality figures

**Solution:** Increase DPI:

```python
plt.savefig('figures/data/my_plot.png', dpi=300)  # or 600 for publications
```

---

## Additional Resources

- **Matplotlib documentation:** https://matplotlib.org/stable/
- **Seaborn documentation:** https://seaborn.pydata.org/
- **Visualization best practices:** [`src/viz_utils.py`](../src/viz_utils.py)

---

*Last updated: 2025-11-13*

