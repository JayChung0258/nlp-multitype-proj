Transformer Model - Classification Report
======================================================================

MODEL: bert-base-uncased
Generated: 2025-11-20T00:44:41.408128Z

TRAINING CONFIGURATION
----------------------------------------------------------------------
Max sequence length:   256
Train batch size:      16
Eval batch size:       32
Epochs:                3.0
Learning rate:         2e-05
Weight decay:          0.01
Warmup ratio:          0.1
Random seed:           42
Trainable parameters:  109,485,316

VALIDATION SET METRICS
----------------------------------------------------------------------
Accuracy:  0.6051
Macro-F1:  0.5897

F1 per class:
  T1 (Human Original):       0.4954
  T2 (LLM Generated):        0.7699
  T3 (Human Paraphrased):    0.3601
  T4 (LLM Paraphrased):      0.7332

TEST SET METRICS (FINAL)
----------------------------------------------------------------------
Accuracy:  0.5949
Macro-F1:  0.5796

F1 per class:
  T1 (Human Original):       0.4852
  T2 (LLM Generated):        0.7696
  T3 (Human Paraphrased):    0.3568
  T4 (LLM Paraphrased):      0.7067

CONFUSION MATRIX (TEST)
----------------------------------------------------------------------
          Predicted
          T1    T2    T3    T4
Actual
  T1     394    77   196    83
  T2      31   658    17    44
  T3     379    84   213    71
  T4      70   141    21   518

EFFICIENCY METRICS
----------------------------------------------------------------------
Training time:     553.07 seconds (9.22 minutes)
Test eval time:    9.27 seconds
Throughput:        1.7 samples/sec

======================================================================
