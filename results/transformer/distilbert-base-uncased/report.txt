Transformer Model - Classification Report
======================================================================

MODEL: distilbert-base-uncased
Generated: 2025-11-13T17:15:05.897751Z

TRAINING CONFIGURATION
----------------------------------------------------------------------
Max sequence length:   256
Train batch size:      16
Eval batch size:       32
Epochs:                3.0
Learning rate:         2e-05
Weight decay:          0.01
Warmup ratio:          0.1
Random seed:           42
Trainable parameters:  66,956,548

VALIDATION SET METRICS
----------------------------------------------------------------------
Accuracy:  0.5848
Macro-F1:  0.5742

F1 per class:
  T1 (Human Original):       0.4728
  T2 (LLM Generated):        0.7637
  T3 (Human Paraphrased):    0.3712
  T4 (LLM Paraphrased):      0.6892

TEST SET METRICS (FINAL)
----------------------------------------------------------------------
Accuracy:  0.5923
Macro-F1:  0.5786

F1 per class:
  T1 (Human Original):       0.4919
  T2 (LLM Generated):        0.7688
  T3 (Human Paraphrased):    0.3508
  T4 (LLM Paraphrased):      0.7027

CONFUSION MATRIX (TEST)
----------------------------------------------------------------------
          Predicted
          T1    T2    T3    T4
Actual
  T1     397    66   193    94
  T2      33   625    23    69
  T3     378    73   214    82
  T4      56   112    43   539

EFFICIENCY METRICS
----------------------------------------------------------------------
Training time:     3315.35 seconds (55.26 minutes)
Test eval time:    84.65 seconds
Throughput:        0.2 samples/sec

======================================================================
