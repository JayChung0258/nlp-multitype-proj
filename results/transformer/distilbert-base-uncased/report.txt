Transformer Model - Classification Report
======================================================================

MODEL: distilbert-base-uncased
Generated: 2025-11-20T00:34:53.783188Z

TRAINING CONFIGURATION
----------------------------------------------------------------------
Max sequence length:   256
Train batch size:      16
Eval batch size:       32
Epochs:                3.0
Learning rate:         2e-05
Weight decay:          0.01
Warmup ratio:          0.1
Random seed:           42
Trainable parameters:  66,956,548

VALIDATION SET METRICS
----------------------------------------------------------------------
Accuracy:  0.5854
Macro-F1:  0.5717

F1 per class:
  T1 (Human Original):       0.4929
  T2 (LLM Generated):        0.7522
  T3 (Human Paraphrased):    0.3554
  T4 (LLM Paraphrased):      0.6861

TEST SET METRICS (FINAL)
----------------------------------------------------------------------
Accuracy:  0.5869
Macro-F1:  0.5718

F1 per class:
  T1 (Human Original):       0.4783
  T2 (LLM Generated):        0.7625
  T3 (Human Paraphrased):    0.3359
  T4 (LLM Paraphrased):      0.7107

CONFUSION MATRIX (TEST)
----------------------------------------------------------------------
          Predicted
          T1    T2    T3    T4
Actual
  T1     397    72   191    90
  T2      48   631    12    59
  T3     396    85   198    68
  T4      69   117    31   533

EFFICIENCY METRICS
----------------------------------------------------------------------
Training time:     285.30 seconds (4.75 minutes)
Test eval time:    4.74 seconds
Throughput:        3.4 samples/sec

======================================================================
